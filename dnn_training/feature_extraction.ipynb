{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "# This file is (was?) in /l/rkarhila/speecon_wsj_phoneme_dnn/data_preprocessing\n",
    "\n",
    "#\n",
    "#  1. Divide each data file into single phoneme chunks based on aliged labels\n",
    "#\n",
    "#  2. Run the chunks through feature extraction shell script\n",
    "#\n",
    "#  3. Store the features and their associated phoneme information in arrays\n",
    "#\n",
    "#  4. Pickle for future normalisation (with other corpora) \n",
    "#\n",
    "\n",
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "import re\n",
    "import math \n",
    "import struct\n",
    "import time\n",
    "import sys\n",
    "import struct\n",
    "import random\n",
    "\n",
    "#\n",
    "# Use some funky structure from tensor flow to store 3d-matrices of variable length more compactly.\n",
    "#\n",
    "import tensorflow as tf\n",
    "\n",
    "#\n",
    "# A function that will be useful:\n",
    "#\n",
    "\n",
    "def mkdir(path):\n",
    "    try:\n",
    "        os.makedirs(path)        \n",
    "    except OSError as exc:  # Python >2.5\n",
    "        #print (\"dir %s exists\" % path)\n",
    "        dummy = 1\n",
    "#\n",
    "# Some more output?\n",
    "#\n",
    "debug=False\n",
    "global debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocessing_scripts = {'none' :{'script': '../feature_extraction_scripts/preprocess_pfstar.sh', 'name' : 'clean', 'parameters': [[0,0], [0,0]] },\n",
    "                         'overdrive' : {'script': '../feature_extraction_scripts/preprocess_pfstar_and_overdrive.sh', 'name' : 'overdrive', 'parameters': [[1,10], [-20,0]] },\n",
    "                         'underdrive' : {'script': '../feature_extraction_scripts/preprocess_pfstar_and_overdrive.sh', 'name' : 'underdrive', 'parameters': [[-40,-20], [0,0]] },\n",
    "                         'babble' : {'script': '../feature_extraction_scripts/preprocess_pfstar_and_add_babble.sh', 'name' : 'babbled', 'parameters': [[-40,-20],[-20,0]] },\n",
    "                         'humming' : {'script': '../feature_extraction_scripts/preprocess_pfstar_and_add_humming.sh', 'name' : 'volvo', 'parameters': [[-30,-20],[-20,0]] } }\n",
    "\n",
    "#feature_extraction_script = '../feature_extraction_scripts/extract_5500hz_spec_with_start_end.sh'\n",
    "feature_extraction_script = '../feature_extraction_scripts/extract_5500hz_mcep_and_lsf_with_start_end.sh'\n",
    "featuretype = \"mcep_and_lsf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using tmp dir /dev/shm/siak-feat-extract-python-1481796019.2509968\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vowels = ['a','A','å','Å','ä','Ä','e','E','f','i','I','o','O','ö','u','U']\n",
    "\n",
    "nonvow = ['b','C','d','D','g','H','j','J','k','l','m','n','N','p','P','Q','r','R','s','S','t','T','v','w','W','Y','z','Z']\n",
    "\n",
    "combinations = []\n",
    "\n",
    "\n",
    "used_classes = vowels+nonvow+combinations\n",
    "classes_name = \"mc_en_uk_all\"\n",
    "\n",
    "\n",
    "#\n",
    "# Settings for feature extraction:\n",
    "#\n",
    "\n",
    "datatypelength = 2 # 16 bits = 2 bytes, no?\n",
    "\n",
    "\n",
    "# For 16 kHz samples:\n",
    "\n",
    "audio_fs = 16000\n",
    "'''\n",
    "frame_length = 400\n",
    "frame_step = 128\n",
    "'''\n",
    "\n",
    "frame_leftovers = frame_length-frame_step\n",
    "\n",
    "padding_array = bytearray()\n",
    "\n",
    "progress_length = 80\n",
    "\n",
    "max_num_samples=8000 # 0.5 should be enough for any reasonable phoneme, right?\n",
    "\n",
    "max_num_classes = 10000\n",
    "\n",
    "#feature_dimension=129\n",
    "feature_dimension=30\n",
    "\n",
    "'''\n",
    "# For 5.6 kHz samples:\n",
    "'''\n",
    "feature_fs = 5500\n",
    "frame_length = 128\n",
    "frame_step = 45\n",
    "\n",
    "\n",
    "\n",
    "max_num_frames=100\n",
    "max_num_monoclasses = 200\n",
    "max_num_monoclasses = 9\n",
    "\n",
    "\n",
    "#max_num_samples=100160\n",
    "assigned_num_samples=100\n",
    "\n",
    "\n",
    "\n",
    "# tmp directory for feature extraction.\n",
    "# This should reside in memory (tempfs or whatever it's called, often under /dev/shm/)\n",
    "\n",
    "tmp_dir=\"/dev/shm/siak-feat-extract-python-\"+str(time.time())\n",
    "try:\n",
    "    os.makedirs(tmp_dir)\n",
    "except OSError as exc:  # Python >2.5\n",
    "    if exc.errno == errno.EEXIST and os.path.isdir(tmp_dir):\n",
    "        pass\n",
    "    else:\n",
    "        raise   \n",
    "\n",
    "\n",
    "print ('using tmp dir %s' % tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes and probabilities ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_def = {\n",
    "\"sil\" : {\"count\" : 6611, \"probability\" :0.04628649220995, \"sqrt_probability\" :0.2151429576118, \"class\" :45},\n",
    "\"P\" : {\"count\" : 306, \"probability\" :1, \"sqrt_probability\" :1, \"class\" :44},\n",
    "\"Z\" : {\"count\" : 311, \"probability\" :0.98392282958199, \"sqrt_probability\" :0.99192884300336, \"class\" :43},\n",
    "\"Å\" : {\"count\" : 344, \"probability\" :0.88953488372093, \"sqrt_probability\" :0.94315156985552, \"class\" :42},\n",
    "\"U\" : {\"count\" : 497, \"probability\" :0.61569416498994, \"sqrt_probability\" :0.78466181568236, \"class\" :41},\n",
    "\"W\" : {\"count\" : 501, \"probability\" :0.61077844311377, \"sqrt_probability\" :0.78152315583978, \"class\" :40},\n",
    "\"ö\" : {\"count\" : 573, \"probability\" :0.53403141361257, \"sqrt_probability\" :0.73077452994242, \"class\" :39},\n",
    "\"å\" : {\"count\" : 601, \"probability\" :0.50915141430948, \"sqrt_probability\" :0.71354846668568, \"class\" :38},\n",
    "\"S\" : {\"count\" : 641, \"probability\" :0.47737909516381, \"sqrt_probability\" :0.69092625884663, \"class\" :37},\n",
    "\"C\" : {\"count\" : 746, \"probability\" :0.41018766756032, \"sqrt_probability\" :0.64045895072231, \"class\" :36},\n",
    "\"J\" : {\"count\" : 757, \"probability\" :0.40422721268164, \"sqrt_probability\" :0.63578865409949, \"class\" :35},\n",
    "\"A\" : {\"count\" : 958, \"probability\" :0.31941544885177, \"sqrt_probability\" :0.56516851367692, \"class\" :34},\n",
    "\"N\" : {\"count\" : 958, \"probability\" :0.31941544885177, \"sqrt_probability\" :0.56516851367692, \"class\" :33},\n",
    "\"H\" : {\"count\" : 963, \"probability\" :0.31775700934579, \"sqrt_probability\" :0.56369939626169, \"class\" :32},\n",
    "\"R\" : {\"count\" : 1050, \"probability\" :0.29142857142857, \"sqrt_probability\" :0.53984124650546, \"class\" :31},\n",
    "\"T\" : {\"count\" : 1057, \"probability\" :0.28949858088931, \"sqrt_probability\" :0.53805072334243, \"class\" :30},\n",
    "\"j\" : {\"count\" : 1132, \"probability\" :0.27031802120141, \"sqrt_probability\" :0.5199211682567, \"class\" :29},\n",
    "\"Y\" : {\"count\" : 1354, \"probability\" :0.22599704579025, \"sqrt_probability\" :0.47539146583658, \"class\" :28},\n",
    "\"g\" : {\"count\" : 1420, \"probability\" :0.21549295774648, \"sqrt_probability\" :0.46421219043287, \"class\" :27},\n",
    "\"u\" : {\"count\" : 1621, \"probability\" :0.18877236273905, \"sqrt_probability\" :0.4344794157829, \"class\" :26},\n",
    "\"o\" : {\"count\" : 1648, \"probability\" :0.18567961165049, \"sqrt_probability\" :0.4309055716169, \"class\" :25},\n",
    "\"w\" : {\"count\" : 1675, \"probability\" :0.18268656716418, \"sqrt_probability\" :0.42741849183696, \"class\" :24},\n",
    "\"ä\" : {\"count\" : 1742, \"probability\" :0.17566016073479, \"sqrt_probability\" :0.41911831352828, \"class\" :23},\n",
    "\"p\" : {\"count\" : 1773, \"probability\" :0.17258883248731, \"sqrt_probability\" :0.41543812112914, \"class\" :22},\n",
    "\"E\" : {\"count\" : 1807, \"probability\" :0.16934144991699, \"sqrt_probability\" :0.41151117836213, \"class\" :21},\n",
    "\"D\" : {\"count\" : 1819, \"probability\" :0.16822429906542, \"sqrt_probability\" :0.4101515562148, \"class\" :20},\n",
    "\"O\" : {\"count\" : 1843, \"probability\" :0.16603364080304, \"sqrt_probability\" :0.4074722577097, \"class\" :19},\n",
    "\"b\" : {\"count\" : 2129, \"probability\" :0.14372945044622, \"sqrt_probability\" :0.379116671285, \"class\" :18},\n",
    "\"m\" : {\"count\" : 2177, \"probability\" :0.140560404226, \"sqrt_probability\" :0.37491386240842, \"class\" :17},\n",
    "\"v\" : {\"count\" : 2227, \"probability\" :0.13740458015267, \"sqrt_probability\" :0.37068123792913, \"class\" :16},\n",
    "\"e\" : {\"count\" : 2298, \"probability\" :0.1331592689295, \"sqrt_probability\" :0.36490994632855, \"class\" :15},\n",
    "\"d\" : {\"count\" : 2410, \"probability\" :0.12697095435685, \"sqrt_probability\" :0.35632983927374, \"class\" :14},\n",
    "\"a\" : {\"count\" : 2582, \"probability\" :0.11851278079009, \"sqrt_probability\" :0.34425685293119, \"class\" :13},\n",
    "\"I\" : {\"count\" : 2608, \"probability\" :0.11733128834356, \"sqrt_probability\" :0.3425365503761, \"class\" :12},\n",
    "\"f\" : {\"count\" : 2690, \"probability\" :0.11375464684015, \"sqrt_probability\" :0.33727532794462, \"class\" :11},\n",
    "\"Ä\" : {\"count\" : 2795, \"probability\" :0.10948121645796, \"sqrt_probability\" :0.33087945910552, \"class\" :10},\n",
    "\"z\" : {\"count\" : 3066, \"probability\" :0.09980430528376, \"sqrt_probability\" :0.31591819397394, \"class\" :9},\n",
    "\"k\" : {\"count\" : 3292, \"probability\" :0.09295261239368, \"sqrt_probability\" :0.30488130869845, \"class\" :8},\n",
    "\"l\" : {\"count\" : 3619, \"probability\" :0.08455374412821, \"sqrt_probability\" :0.2907812650915, \"class\" :7},\n",
    "\"r\" : {\"count\" : 3630, \"probability\" :0.08429752066116, \"sqrt_probability\" :0.29034035313948, \"class\" :6},\n",
    "\"Q\" : {\"count\" : 4684, \"probability\" :0.06532877882152, \"sqrt_probability\" :0.25559495069645, \"class\" :5},\n",
    "\"s\" : {\"count\" : 4867, \"probability\" :0.06287240599959, \"sqrt_probability\" :0.25074370580254, \"class\" :4},\n",
    "\"i\" : {\"count\" : 5140, \"probability\" :0.05953307392996, \"sqrt_probability\" :0.24399400388116, \"class\" :3},\n",
    "\"t\" : {\"count\" : 5996, \"probability\" :0.05103402268179, \"sqrt_probability\" :0.22590711073755, \"class\" :2},\n",
    "\"n\" : {\"count\" : 6811, \"probability\" :0.04492732344736, \"sqrt_probability\" :0.21196066485875, \"class\" :1},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Dataset definitions ##\n",
    "*In a very awkward manner, we'll specify some local files that contain list of audio and transcription files*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "#   Data collection defitinions - train, dev and eval sets:\n",
    "#\n",
    "\n",
    "\n",
    "corpus = \"en_uk_kids_align_from_clean\"\n",
    "pickle_dir='../features/work_in_progress/'+corpus+'/pickles'\n",
    "statistics_dir = '../features/work_in_progress/'+corpus+'/statistics/'\n",
    "\n",
    "collections = [                                                                                                          \n",
    "    { 'name' : 'train-0',\n",
    "      'recipe' : '/l/rkarhila/speecon_wsj_phoneme_dnn/kids_en_uk/leave_one_out_recipes/recipe.speakers.train.00',\n",
    "      'condition' : 'clean',\n",
    "      'numlines': 878 },\n",
    "    { 'name' : 'train-1',\n",
    "      'recipe' : '/l/rkarhila/speecon_wsj_phoneme_dnn/kids_en_uk/leave_one_out_recipes/recipe.speakers.train.01',\n",
    "      'condition' : 'clean',\n",
    "      'numlines': 1083 },\n",
    "    { 'name' : 'train-2',\n",
    "      'recipe' : '/l/rkarhila/speecon_wsj_phoneme_dnn/kids_en_uk/leave_one_out_recipes/recipe.speakers.train.02',\n",
    "      'condition' : 'clean',\n",
    "      'numlines': 946 },\n",
    "    { 'name' : 'train-3',\n",
    "      'recipe' : '/l/rkarhila/speecon_wsj_phoneme_dnn/kids_en_uk/leave_one_out_recipes/recipe.speakers.train.03',\n",
    "      'condition' : 'clean',\n",
    "      'numlines': 870 },\n",
    "    { 'name' : 'train-4',\n",
    "      'recipe' : '/l/rkarhila/speecon_wsj_phoneme_dnn/kids_en_uk/leave_one_out_recipes/recipe.speakers.train.04',\n",
    "      'condition' : 'clean',\n",
    "      'numlines': 651 },\n",
    "    { 'name' : 'train-5',\n",
    "      'recipe' : '/l/rkarhila/speecon_wsj_phoneme_dnn/kids_en_uk/leave_one_out_recipes/recipe.speakers.train.05',\n",
    "      'condition' : 'clean',\n",
    "      'numlines': 785},\n",
    "    { 'name' : 'train-6',\n",
    "      'recipe' : '/l/rkarhila/speecon_wsj_phoneme_dnn/kids_en_uk/leave_one_out_recipes/recipe.speakers.train.06',\n",
    "      'condition' : 'clean',\n",
    "      'numlines': 699 },\n",
    "    { 'name' : 'train-7',\n",
    "      'recipe' : '/l/rkarhila/speecon_wsj_phoneme_dnn/kids_en_uk/leave_one_out_recipes/recipe.speakers.train.07',\n",
    "      'condition' : 'clean',\n",
    "      'numlines': 699 },\n",
    "    { 'name' : 'test-0',\n",
    "      'recipe' : '/l/rkarhila/speecon_wsj_phoneme_dnn/kids_en_uk/leave_one_out_recipes/recipe.speakers.test.00',\n",
    "      'condition' : 'clean',\n",
    "      'numlines': 852 },\n",
    "    { 'name' : 'test-1',\n",
    "      'recipe' : '/l/rkarhila/speecon_wsj_phoneme_dnn/kids_en_uk/leave_one_out_recipes/recipe.speakers.test.01',\n",
    "      'condition' : 'clean',\n",
    "      'numlines': 752 },\n",
    "    { 'name' : 'test-2',\n",
    "      'recipe' : '/l/rkarhila/speecon_wsj_phoneme_dnn/kids_en_uk/leave_one_out_recipes/recipe.speakers.test.02',\n",
    "      'condition' : 'clean',\n",
    "      'numlines': 594 },\n",
    "    { 'name' : 'test-3',\n",
    "      'recipe' : '/l/rkarhila/speecon_wsj_phoneme_dnn/kids_en_uk/leave_one_out_recipes/recipe.speakers.test.03',\n",
    "      'condition' : 'clean',\n",
    "      'numlines': 758 },\n",
    "    { 'name' : 'test-4',\n",
    "      'recipe' : '/l/rkarhila/speecon_wsj_phoneme_dnn/kids_en_uk/leave_one_out_recipes/recipe.speakers.test.04',\n",
    "      'condition' : 'clean',\n",
    "      'numlines': 734 },\n",
    "    { 'name' : 'eval-1',\n",
    "      'recipe' : '/l/rkarhila/speecon_wsj_phoneme_dnn/kids_en_uk/leave_one_out_recipes/recipe.speakers.test.05',\n",
    "      'condition' : 'clean',\n",
    "      'numlines': 393},\n",
    "    { 'name' : 'eval-0',\n",
    "      'recipe' : '/l/rkarhila/speecon_wsj_phoneme_dnn/kids_en_uk/leave_one_out_recipes/recipe.speakers.eval.00',\n",
    "      'condition' : 'clean',\n",
    "      'numlines': 837 }\n",
    "]\n",
    "\n",
    "\n",
    "featdim1 = -1;\n",
    "featdim2 = -1;\n",
    "\n",
    "means_set = False\n",
    "means = -1;\n",
    "stds = -1;\n",
    "new_pickle_dir = \"-1\"\n",
    "\n",
    "classes = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helper functions ##\n",
    "*Label processing etc.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_label( labelfile ):\n",
    "    global debug\n",
    "    \n",
    "    if not os.path.isfile(labelfile):\n",
    "        print (\"Can't find labelfile %s\" % labelfile)\n",
    "        return False\n",
    "    \n",
    "    with io.open(labelfile ,'r',encoding='iso-8859-15') as f:\n",
    "\n",
    "        new_align = []\n",
    "\n",
    "        current_start = 0\n",
    "        current_end = 0\n",
    "        current_model = False\n",
    "        current_premodel = False\n",
    "        current_postmodel = False\n",
    "\n",
    "        skip = False\n",
    "\n",
    "        phonect = 0\n",
    "        statect = 0\n",
    "\n",
    "        lcounter = 0\n",
    "\n",
    "        # For printing the phoneme sequences into a log:\n",
    "        skipmark=False\n",
    "\n",
    "        startmark=-1\n",
    "        endmark = -1\n",
    "\n",
    "        discard = False\n",
    "        sildone = False\n",
    "        phone={}\n",
    "\n",
    "        for l in  f.readlines():\n",
    "            \n",
    "            \n",
    "            # If we have a short pause model:\n",
    "            #if '+' not in l:\n",
    "            #    no_skipping = True\n",
    "            #    skipmark = True\n",
    "\n",
    "            # We'll process the label line by line with a two-phone delay:\n",
    "\n",
    "            if '+' in l and not discard:\n",
    "                #print \"Looking at %s\"%(l)\n",
    "                [start, \n",
    "                 end, \n",
    "                 premodel, \n",
    "                 model, \n",
    "                 postmodel, \n",
    "                 state] = re.split(r'[ .+-]', l.strip() ) #, l.encode('utf-8').strip() )\n",
    "\n",
    "                if state=='0':\n",
    "\n",
    "                    phone = {'start':start, \n",
    "                             'premodel':premodel, \n",
    "                             'model': model,\n",
    "                             'postmodel':postmodel,\n",
    "                             'state':state,\n",
    "                             'triphone': \"%s-%s+%s\" % (premodel, model, postmodel) }\n",
    "\n",
    "                if state=='2':\n",
    "                    phone['end'] = end\n",
    "\n",
    "                    if (phone['model'] != '__'):\n",
    "\n",
    "                        if (int(phone['end'])-int(phone['start']))/frame_step == 3:\n",
    "                            #discard_counter+=1\n",
    "                            #print \"Discarding %i/%i: %s: (Too short! Discards: %0.2f%s)\" % (recipefilecounter, collection['numlines'], labelfile, 100.0*discard_counter/collection['numlines'],\"%\" )\n",
    "\n",
    "                            discard = True\n",
    "\n",
    "                        #elif (int(phone['end'])-int(phone['start']))/frame_step > 40 and '_' not in phone['triphone']:\n",
    "                        #    #print \"Discarding %i/%i: %s (Too Long! Discards: %0.2f%s)\" % (recipefilecounter, collection['numlines'], labelfile, 100.0*discard_counter/collection['numlines'],\"%\" )\n",
    "                        #    discard_counter+=1\n",
    "                        #    discard = True\n",
    "\n",
    "                        #if debug:\n",
    "                        #    print (\"saving %s-%s+%s \" %  (phone['premodel'], phone['model'],phone['postmodel']))\n",
    "                        else:\n",
    "                            new_align.append({'pre' : phone['premodel'],\n",
    "                                          'model' : phone['model'],\n",
    "                                          'post' : phone['postmodel'],\n",
    "                                          'start' : phone['start'],\n",
    "                                          'end' : phone['end'],\n",
    "                                          'triphone' : phone['triphone'],\n",
    "                                          'sortable': \"%s--%s++%s\" % (phone['model'] , phone['premodel'], phone['postmodel'])\n",
    "                                      })\n",
    "            elif not sildone:\n",
    "                [start, \n",
    "                 end, \n",
    "                 model, \n",
    "                 state] = re.split(r'[ .]', l.strip() )\n",
    "                \n",
    "                if state=='2':\n",
    "                    new_align.append( {'pre' : '?',\n",
    "                                       'model' : 'sil',\n",
    "                                       'post' : '?',\n",
    "                                       'start' : max(0, int(end)-16000 ),\n",
    "                                       'end' : int(end),\n",
    "                                       'triphone' : 'sil',\n",
    "                                       'sortable': 'sil-?+?' })\n",
    "                    sildone = True\n",
    "\n",
    "\n",
    "\n",
    "    return new_align\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_labelstring( new_align ):\n",
    "    labelstring = ''\n",
    "    for phone in new_align:\n",
    "        labelstring += '.'+phone['model']\n",
    "    return labelstring    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chop_features( cleanaudiodata, noisyaudiodata, noisy_feature_array, clean_feature_array, new_align, speedup, preprocessor_string, \n",
    "                   cleanphonedata, noisyphonedata, phoneclasses, phone_indices, segment_details, segment_lengths, quality_control_audio_files ):\n",
    "    global debug\n",
    "    \n",
    "    count = 0\n",
    "    startmark = int(math.ceil(float(new_align[0]['start'])*(feature_fs/audio_fs)/speedup))\n",
    "    endmark= int(math.floor(float(new_align[-1]['end'])*(feature_fs/audio_fs)/speedup))\n",
    "    \n",
    "    tooshortcount=0\n",
    "    \n",
    "    for l in new_align:                \n",
    "\n",
    "        lkey = l['sortable']\n",
    "        mkey = l['model']\n",
    "        \n",
    "        if 1 == 1:\n",
    "            tp = l['triphone']\n",
    "\n",
    "            l_start = math.ceil((float(l['start'])/speedup-startmark)*(feature_fs/audio_fs)/frame_step)\n",
    "            l_end =  math.floor((float(l['end'])/speedup-startmark)*(feature_fs/audio_fs)/frame_step)            \n",
    "            l_length = l_end - l_start\n",
    "            \n",
    "            if debug:\n",
    "                print (\"Segment length: %i\" % l_length)\n",
    "            if (l_length < 4):\n",
    "                tooshortcount+=1\n",
    "                continue\n",
    "\n",
    "            # For debugging, let's write this stuff to disk:\n",
    "            if mkey not in quality_control_audio_files.keys():\n",
    "                qual_file = os.path.join(quality_control_wavdir,  mkey+\".raw-\"+str(feature_fs)+\"hz-16bit-signed-integer\")\n",
    "                quality_control_audio_files[mkey] = open( qual_file , 'wb')\n",
    "\n",
    "            win_i=0\n",
    "            win_len=256\n",
    "            max_val=32000\n",
    "            \n",
    "            audio_start = int(math.floor(float(l['start'])/speedup*(feature_fs/audio_fs)))\n",
    "            audio_end = int(math.ceil(float(l['end'])/speedup*(feature_fs/audio_fs)))\n",
    "            \n",
    "            if debug:\n",
    "                print(\"start: %i end: %i audiodata len: %i\" %(audio_start, audio_end, len(noisyaudiodata)))\n",
    "            if audio_end > len(noisyaudiodata):\n",
    "                raise ValueError(\"Can't access %i:%i in audiofile of length %i (%s)\"% \n",
    "                                 ( audio_start, audio_end , len(noisyaudiodata), preprocessor_string )) \n",
    "                \n",
    "            norm=20000.0/max(abs(noisyaudiodata[audio_start:audio_end]))\n",
    "            #print norm\n",
    "\n",
    "            for val in noisyaudiodata[audio_start:audio_start+win_len]:\n",
    "                (quality_control_audio_files[mkey]).write( \n",
    "                        struct.pack( 'h', int( max( -max_val, min( max_val,norm * val * win_i / win_len ) ) ) ) )\n",
    "                win_i+=1\n",
    "\n",
    "            for val in noisyaudiodata[audio_start+win_len:audio_end-win_len]:\n",
    "                (quality_control_audio_files[mkey]).write(\n",
    "                        struct.pack( 'h', int(max( -max_val, min(max_val,norm * val ) ) ) ) )\n",
    "\n",
    "            for val in noisyaudiodata[audio_end-win_len:audio_end]:\n",
    "                (quality_control_audio_files[mkey]).write(\n",
    "                        struct.pack( 'h', int(max( -max_val,min(max_val,norm * val * win_i / win_len ) ) ) )  )\n",
    "                win_i-=1\n",
    "\n",
    "            for val in range(0,1024):\n",
    "                (quality_control_audio_files[mkey]).write(\n",
    "                        struct.pack( 'h', 0 ) ) \n",
    "\n",
    "\n",
    "\n",
    "            if (noisy_feature_array.shape[0] < l_end):\n",
    "                print (\"Not enough features: %i < %i\" % (noisy_feature_array.shape[0], l_end))\n",
    "                continue\n",
    "\n",
    "            statistics_handle.write(\"%i\\t%s\\n\" % (l_length, tp))\n",
    "\n",
    "            if debug:\n",
    "                print (\"----------- \"+l['triphone'] +\" ----------------\")\n",
    "                print (\"Array stats: start %i -> %i length ?? -> %i end %i -> %i\" % (\n",
    "                            int(l['start'])-startmark, \n",
    "                            l_start, \n",
    "                            l_length, \n",
    "                            int(l['end'])-startmark, \n",
    "                            l_end ))\n",
    "                print (\"      phone data size: %i x %i\" % (noisy_feature_array[l_start:l_end, :]).shape)\n",
    "                print (\"Data size: %i x %i\" % noisy_feature_array.shape)\n",
    "\n",
    "            index = np.count_nonzero(phoneclasses)\n",
    "\n",
    "            #if index >= len(phoneclasses):\n",
    "            #    print(\"Adding 1000 more entries to phonedata\")\n",
    "            #    phoneclasses = np.concatenate( (phoneclasses, np.zeros([1000], dtype='uint8') ) )\n",
    "            #    segment_lengths = np.concatenate( (segment_lengths, np.zeros([1000], dtype='uint32') ) )\n",
    "            #    phone_indices = np.concatenate( (phone_indices, np.zeros([1000,2], dtype='uint32') ) )\n",
    "                \n",
    "            segment_lengths[index] = l_length\n",
    "            phoneclasses[index] =  class_def[l['model']]['class']\n",
    "            \n",
    "            segment_details.append( l['triphone'] + ' ' + preprocessor_string )\n",
    "            \n",
    "            if index == 0:\n",
    "                phone_indices[index, :] = [0, l_length]\n",
    "            else:\n",
    "                phone_indices[index, :] = [ phone_indices[index-1][1] + 1, \n",
    "                                            phone_indices[index-1][1] + 1 + l_length ]\n",
    "                \n",
    "            #if phone_indices[index, 1] > phonedata.shape[0]:\n",
    "            #    print(\"Adding 50000 more entries to phonedata\")\n",
    "            #    phonedata = np.concatenate( (phonedata, np.zeros([50000, feature_dimension], dtype='float32')), axis=0)\n",
    "                \n",
    "            noisyphonedata[ phone_indices[index][0]:phone_indices[index][1], :] = noisy_feature_array[l_start:l_end, :]\n",
    "            cleanphonedata[ phone_indices[index][0]:phone_indices[index][1], :] = clean_feature_array[l_start:l_end, :]\n",
    "            \n",
    "            count += 1\n",
    "            #phonedata.append(feature_array[l_start:l_end, :])\n",
    "            #triphoneclasses.append( )\n",
    "            #segment_lengths.append( l_length  )\n",
    "            #triphonedata.append ({ 'data': feature_array[l_start:l_start+max_num_frames, :],\n",
    "            #                        'counter': 0,\n",
    "            #                        'mono' :l['model'],\n",
    "            #                        'triphone' : l['triphone'],\n",
    "            #                        'sorting' : l['sortable'] })\n",
    "\n",
    "    return count        \n",
    "    #return { \"data\" : triphonedata, \n",
    "    #         \"classes\" : triphoneclasses, \n",
    "    #         \"segment_lengths\" : segment_lengths }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction (spectral/vocoder parameters) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_features( audiofile, align,  preprocessors, cleanphonedata, noisyphonedata, phoneclasses, phone_indices, \n",
    "                  segment_details, segment_lengths, quality_control_audio_files, training=True):\n",
    "    global debug\n",
    "    count = 0\n",
    "    errors = []\n",
    "    \n",
    "    if training:\n",
    "        speedups =  [0.9, 1.0, 1.1 ]      \n",
    "    else:\n",
    "        speedups = [1.0]\n",
    "        \n",
    "    for speedup in speedups:\n",
    "\n",
    "        new_align = [];\n",
    "        for l in align:                \n",
    "            if random.random() < class_def[l['model']][\"probability\"]:\n",
    "                new_align.append(l)\n",
    "        if debug:\n",
    "            print(new_align)\n",
    "        \n",
    "        if len(new_align) > 0:\n",
    "            \n",
    "            preprocessor_key = preprocessors[random.randint( 0, len(preprocessors)-1 ) ]\n",
    "            \n",
    "            noisy_preprocessor = preprocessing_scripts[preprocessor_key]\n",
    "                                                                    \n",
    "            noisy_preprocessed_audio=os.path.join(tmp_dir,\n",
    "                                            str(tmpfilecounter)+\"_\"+str(speedup)+\"_preprocessed\")\n",
    "\n",
    "            \n",
    "            clean_preprocessor = preprocessing_scripts['none']\n",
    "\n",
    "            clean_preprocessed_audio = os.path.join(tmp_dir,\n",
    "                                            str(tmpfilecounter)+\"_\"+str(speedup)+\"_clean\")\n",
    "            #for preprocessor in preprocessors:\n",
    "            #    preprocessor =  preprocessing_scripts[random.randint(0, len(preprocessing_scripts)-1)]\n",
    "    \n",
    "            if 1 == 1:\n",
    "                if debug:\n",
    "                    print (\"Preprocessor : %s\" % noisy_preprocessor['name'])\n",
    "    \n",
    "                if noisy_preprocessor['parameters'][0][1] - noisy_preprocessor['parameters'][0][0] > 0:\n",
    "                    param1 = str(random.randint( noisy_preprocessor['parameters'][0][0],\n",
    "                                                 noisy_preprocessor['parameters'][0][1]) )\n",
    "                else:\n",
    "                    param1 = str(noisy_preprocessor['parameters'][0][0])\n",
    "    \n",
    "\n",
    "                if noisy_preprocessor['parameters'][1][1] - noisy_preprocessor['parameters'][1][0] > 0:                    \n",
    "                    param2 = str(random.randint( noisy_preprocessor['parameters'][1][0],\n",
    "                                                 noisy_preprocessor['parameters'][1][1]) )\n",
    "                else:\n",
    "                    param2 = str(noisy_preprocessor['parameters'][1][0])\n",
    "    \n",
    "                preprocessor_string = (\"%s %s %s %.1f %s\" % (preprocessor_key , param1, param2, speedup, audiofile))\n",
    "        \n",
    "                if debug:                    \n",
    "                    print (' '.join([noisy_preprocessor['script'],\n",
    "                                     audiofile,\n",
    "                                     noisy_preprocessed_audio,\n",
    "                                     str(speedup),\n",
    "                                     param1,\n",
    "                                     param2\n",
    "                                 ]))\n",
    "\n",
    "                preprocess_progress = Popen([noisy_preprocessor['script'],\n",
    "                                             audiofile,\n",
    "                                             noisy_preprocessed_audio,\n",
    "                                             str(speedup),\n",
    "                                             param1,\n",
    "                                             param2\n",
    "                                        ], stdout=PIPE, stdin=PIPE, stderr=STDOUT).communicate()\n",
    "\n",
    "                \n",
    "                clean_preprocess_progress = Popen([clean_preprocessor['script'],\n",
    "                                             audiofile,\n",
    "                                             clean_preprocessed_audio,\n",
    "                                             str(speedup),\n",
    "                                             param1,\n",
    "                                             param2\n",
    "                                        ], stdout=PIPE, stdin=PIPE, stderr=STDOUT).communicate()\n",
    "                \n",
    "\n",
    "                noisy_audiodata = np.fromfile( noisy_preprocessed_audio, 'int16', -1)\n",
    "                clean_audiodata = np.fromfile( clean_preprocessed_audio, 'int16', -1)\n",
    "\n",
    "                startmark = float(new_align[0]['start'])/speedup\n",
    "                endmark= float(new_align[-1]['end'])/speedup\n",
    "\n",
    "                if debug:\n",
    "                    print (\"start feature extraction at %s (%f s) and end at %s (%f s) ==> %i frames\"  % (\n",
    "                            startmark, \n",
    "                            (float(startmark)/16000), \n",
    "                            endmark, (float(endmark)/16000), \n",
    "                            (endmark-startmark)/frame_step) )\n",
    "\n",
    "                # Communication from: \n",
    "                # http://stackoverflow.com/questions/163542/python-how-do-i-pass-a-string-into-subprocess-popen-using-the-stdin-argument\n",
    "\n",
    "                noisy_tmp_input=os.path.join(tmp_dir,str(tmpfilecounter)+\"_noisy_in\")\n",
    "                noisy_tmp_output=os.path.join(tmp_dir,str(tmpfilecounter)+\"_noisy_out\")\n",
    "                noisy_audiodata.tofile(noisy_tmp_input, \"\")\n",
    "\n",
    "                clean_tmp_input=os.path.join(tmp_dir,str(tmpfilecounter)+\"_clean_in\")\n",
    "                clean_tmp_output=os.path.join(tmp_dir,str(tmpfilecounter)+\"_clean_out\")\n",
    "\n",
    "                clean_audiodata.tofile(clean_tmp_input, \"\")\n",
    "\n",
    "                process_progress = Popen([\n",
    "                        feature_extraction_script, \n",
    "                        noisy_tmp_input, \n",
    "                        noisy_tmp_output, \n",
    "                        str(startmark), \n",
    "                        str(endmark+frame_leftovers) ], \n",
    "                                         stdout=PIPE, stdin=PIPE, stderr=STDOUT).communicate()\n",
    "\n",
    "                process_progress = Popen([\n",
    "                        feature_extraction_script, \n",
    "                        clean_tmp_input, \n",
    "                        clean_tmp_output, \n",
    "                        str(startmark), \n",
    "                        str(endmark+frame_leftovers) ], \n",
    "                                         stdout=PIPE, stdin=PIPE, stderr=STDOUT).communicate()\n",
    "                \n",
    "                noisy_feature_list = np.fromfile(noisy_tmp_output, dtype='float32', count=-1)\n",
    "                noisy_feature_array = noisy_feature_list.reshape([-1,feature_dimension])\n",
    "\n",
    "                clean_feature_list = np.fromfile(clean_tmp_output, dtype='float32', count=-1)\n",
    "                clean_feature_array = clean_feature_list.reshape([-1,feature_dimension])\n",
    "\n",
    "                \n",
    "                f_end =  math.floor((endmark-startmark)/frame_step)\n",
    "\n",
    "                if debug:\n",
    "                    print (\"Utterance data size: %i x %i\" % (noisy_feature_array).shape)\n",
    "\n",
    "                if (noisy_feature_array.shape[0] < f_end/16000*fs):\n",
    "                        print (\"Not enough noisy features for file %s: %i < %i\" % \n",
    "                               (audiofile, noisy_feature_array.shape[0], f_end))\n",
    "                        print (\"panic save to /tmp/this_is_not_good\")\n",
    "                        np.savetxt('/tmp/this_is_not_good', noisy_feature_array, delimiter='\\t')\n",
    "                        raise ValueError(\"Not enough features for file %s: %i < %i\" % (\n",
    "                                audiofile, \n",
    "                                noisy_feature_array.shape[0], \n",
    "                                f_end) )\n",
    "                        \n",
    "                if (clean_feature_array.shape[0] < f_end/16000*fs):\n",
    "                        print (\"Not enough clean features for file %s: %i < %i\" % \n",
    "                               (audiofile, clean_feature_array.shape[0], f_end))\n",
    "                        print (\"panic save to /tmp/this_is_not_good\")\n",
    "                        np.savetxt('/tmp/this_is_not_good', clean_feature_array, delimiter='\\t')\n",
    "                        raise ValueError(\"Not enough features for file %s: %i < %i\" % (\n",
    "                                audiofile, \n",
    "                                clean_feature_array.shape[0], \n",
    "                                f_end) )                        \n",
    "                        \n",
    "                else:\n",
    "                    try: \n",
    "                        count += chop_features( clean_audiodata,\n",
    "                                               noisy_audiodata,\n",
    "                                               clean_feature_array,\n",
    "                                                          noisy_feature_array, \n",
    "                                                          new_align, \n",
    "                                                          speedup,\n",
    "                                                          preprocessor_string,\n",
    "                                                          cleanphonedata, \n",
    "                                                          noisyphonedata,\n",
    "                                                          phoneclasses, \n",
    "                                                          phone_indices,\n",
    "                                                          segment_details,\n",
    "                                                          segment_lengths,\n",
    "                                                          quality_control_audio_files)\n",
    "                        #triphonedata += data_and_classes[\"data\"]\n",
    "                        #triphoneclasses += data_and_classes[\"classes\"]\n",
    "                        #segment_lengths += data_and_classes[\"segment_lengths\"]\n",
    "\n",
    "                    except ValueError as error:   \n",
    "                        print (error)\n",
    "                        errors.append(\"Bad amount of data! in %s speedup %s\" % (audiofile, speedup))\n",
    "                        continue\n",
    "\n",
    "                os.remove(clean_preprocessed_audio)\n",
    "                os.remove(clean_tmp_input)\n",
    "                os.remove(clean_tmp_output)\n",
    "                \n",
    "                os.remove(noisy_preprocessed_audio)\n",
    "                os.remove(noisy_tmp_input)\n",
    "                os.remove(noisy_tmp_output)\n",
    "\n",
    "    if len(errors)>1:\n",
    "        print (errors[-1])\n",
    "    return { \"errors\": errors, \"count\" : count }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_collection_and_save( collection ):\n",
    "    cleanphonedata = np.zeros([150000,feature_dimension] ,dtype='float32')\n",
    "    noisyphonedata = np.zeros([150000,feature_dimension] ,dtype='float32')\n",
    "    phoneclasses = np.zeros([20000], dtype='uint8')\n",
    "    phone_indices = np.zeros([20000,2], dtype='uint32')\n",
    "    segment_lengths = np.zeros([20000], dtype='uint32')\n",
    "    segment_details = []\n",
    "    \n",
    "    errors = []\n",
    "    quality_control_audio_files = []\n",
    "    \n",
    "    recipefile = open( collection['recipe'] , 'r')\n",
    "    recipefilecounter = 0\n",
    "    too_long_counter = 0\n",
    "    all_trips_counter = 0\n",
    "\n",
    "    tmpfilecounter = 0\n",
    "\n",
    "    progress_interval = math.ceil(collection['numlines']/1000.0)\n",
    "\n",
    "    statistics_file=statistics_dir+\"/\"+corpus+\"-\"+collection['condition']+\"-\"+collection['name']+\".triphone-frame-counts\"\n",
    "    statistics_handle = open(statistics_file, 'w')\n",
    "\n",
    "    class_file=statistics_dir+\"/\"+corpus+\"-\"+collection['condition']+\"-\"+collection['name']+\".triphone-classes\"\n",
    "    class_handle= open(class_file, 'w')\n",
    "\n",
    "    phone_merge_file=statistics_dir+\"/\"+corpus+\"-\"+collection['condition']+\"-\"+collection['name']+\".phone-merge\"\n",
    "    phone_merge_handle = open(phone_merge_file, 'w')\n",
    "\n",
    "    quality_control_wavdir = os.path.join(pickle_dir, 'control-wav', collection['condition']+\"-\"+collection['name']+\"-classes_\"+classes_name)\n",
    "\n",
    "    mkdir(quality_control_wavdir)\n",
    "\n",
    "    quality_control_audio_files = {}\n",
    "\n",
    "    discard_counter=0\n",
    "    tooshortcount=0\n",
    "\n",
    "    for r in recipefile.readlines():\n",
    "        \n",
    "        preprocessors = ['none','overdrive', 'underdrive', 'babble', 'humming']\n",
    "        \n",
    "        recipefilecounter += 1\n",
    "        if debug:\n",
    "            print (\"Item %i/%i\" % (recipefilecounter, collection['numlines']) )\n",
    "\n",
    "        audiofile = re.sub('audio=', r'',  re.findall('audio=/[^ ]+', r)[0]).strip()\n",
    "        labelfile = re.sub(r'transcript=', r'', re.findall('transcript=/[^ ]+', r)[0]).strip()\n",
    "    \n",
    "        new_align = process_label(labelfile)\n",
    "        labelstring = get_labelstring( new_align )\n",
    "        \n",
    "        phone_merge_handle.write(\"%s\\t%s\\n\" % (labelfile, labelstring))\n",
    "\n",
    "        # OK, label file done.\n",
    "        # Now it's time to process the audio.\n",
    "        # We'll send to the feature extractor the bits of the file that \n",
    "        # match the speech segments.\n",
    "\n",
    "        if len(new_align) > 0:\n",
    "            errors_and_count = get_features( audiofile, \n",
    "                                   new_align, \n",
    "                                   preprocessors,\n",
    "                                   cleanphonedata, \n",
    "                                   noisyphonedata,\n",
    "                                   phoneclasses, \n",
    "                                   phone_indices, \n",
    "                                   segment_details,\n",
    "                                   segment_lengths,\n",
    "                                   quality_control_audio_files)\n",
    "            #triphonedata += data_classes_and_errors[\"data\"]\n",
    "            #triphoneclasses += data_classes_and_errors[\"classes\"]\n",
    "            #errors += data_classes_and_errors[\"errors\"]\n",
    "            #segment_lengths += data_classes_and_errors[\"segment_lengths\"]\n",
    "            errors += errors_and_count[\"errors\"]\n",
    "            all_trips_counter += errors_and_count[\"count\"]\n",
    "            #if len(errors_and_count[\"errors\"] ) > 0:\n",
    "            #    print ( errors_and_count[\"errors\"] )\n",
    "\n",
    "        if not debug:\n",
    "            if (recipefilecounter % int(progress_interval)) == 0:\n",
    "                sys.stderr.write(\"\\r%0.2f%s %s %s (%i phones, %i errors)\" % (\n",
    "                        100.0*recipefilecounter/collection['numlines'], \n",
    "                        \"%\",\n",
    "                        collection['condition'], \n",
    "                        collection['name'],\n",
    "                        all_trips_counter,\n",
    "                        len(errors)))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "        if (recipefilecounter == collection['numlines']):\n",
    "            print (\"That's enough!\")\n",
    "            print (\"recipefilecounter %i  == collection['numlines'] %i\" % ( \n",
    "                    recipefilecounter, \n",
    "                    collection['numlines'] ))\n",
    "\n",
    "    itemcount= np.count_nonzero(phoneclasses)\n",
    "    indexcount = phone_indices[itemcount-1,1]\n",
    "    \n",
    "    # Save to a pickle:\n",
    "    import pickle\n",
    "\n",
    "    picklefile = os.path.join(pickle_dir,  collection['name'] + '_' + featuretype + \".pickle\")\n",
    "\n",
    "    mkdir(pickle_dir)            \n",
    "\n",
    "    print (\"pickling %i phones / %i frames to %s\" % ( itemcount, indexcount, picklefile))\n",
    "                        \n",
    "    outf = open(picklefile, 'wb')\n",
    "    # Pickle the list using the highest protocol available.\n",
    "    pickle.dump( {  'cleandata': cleanphonedata[0:indexcount], \n",
    "                    'noisydata': noisyphonedata[0:indexcount], \n",
    "                    'classes': phoneclasses[0:itemcount],\n",
    "                    'indices' : phone_indices[0:itemcount,:],\n",
    "                    'lengths' : segment_lengths[0:itemcount],\n",
    "                    'details' : segment_details }, outf, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.00% clean train-0 (4724 phones, 0 errors)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's enough!\n",
      "recipefilecounter 878  == collection['numlines'] 878\n",
      "pickling 4724 phones / 111796 frames to ../features/work_in_progress/en_uk_kids_align_from_clean/pickles/train-0_mcep_and_lsf.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99.91% clean train-1 (5176 phones, 0 errors)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's enough!\n",
      "recipefilecounter 1083  == collection['numlines'] 1083\n",
      "pickling 5181 phones / 115144 frames to ../features/work_in_progress/en_uk_kids_align_from_clean/pickles/train-1_mcep_and_lsf.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.00% clean train-2 (4935 phones, 0 errors)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's enough!\n",
      "recipefilecounter 946  == collection['numlines'] 946\n",
      "pickling 4935 phones / 106514 frames to ../features/work_in_progress/en_uk_kids_align_from_clean/pickles/train-2_mcep_and_lsf.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.15% clean train-4 (0 phones, 0 errors)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's enough!\n",
      "recipefilecounter 870  == collection['numlines'] 870\n",
      "pickling 5533 phones / 101351 frames to ../features/work_in_progress/en_uk_kids_align_from_clean/pickles/train-3_mcep_and_lsf.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.00% clean train-4 (3786 phones, 0 errors)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's enough!\n",
      "recipefilecounter 651  == collection['numlines'] 651\n",
      "pickling 3786 phones / 80373 frames to ../features/work_in_progress/en_uk_kids_align_from_clean/pickles/train-4_mcep_and_lsf.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.00% clean train-5 (5578 phones, 0 errors)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's enough!\n",
      "recipefilecounter 785  == collection['numlines'] 785\n",
      "pickling 5578 phones / 103627 frames to ../features/work_in_progress/en_uk_kids_align_from_clean/pickles/train-5_mcep_and_lsf.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.00% clean train-6 (5014 phones, 0 errors)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's enough!\n",
      "recipefilecounter 699  == collection['numlines'] 699\n",
      "pickling 5014 phones / 98587 frames to ../features/work_in_progress/en_uk_kids_align_from_clean/pickles/train-6_mcep_and_lsf.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.00% clean train-7 (4377 phones, 0 errors)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's enough!\n",
      "recipefilecounter 699  == collection['numlines'] 699\n",
      "pickling 4377 phones / 78395 frames to ../features/work_in_progress/en_uk_kids_align_from_clean/pickles/train-7_mcep_and_lsf.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.00% clean test-0 (5123 phones, 0 errors)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's enough!\n",
      "recipefilecounter 852  == collection['numlines'] 852\n",
      "pickling 5123 phones / 101487 frames to ../features/work_in_progress/en_uk_kids_align_from_clean/pickles/test-0_mcep_and_lsf.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.00% clean test-1 (3629 phones, 0 errors)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's enough!\n",
      "recipefilecounter 752  == collection['numlines'] 752\n",
      "pickling 3629 phones / 87612 frames to ../features/work_in_progress/en_uk_kids_align_from_clean/pickles/test-1_mcep_and_lsf.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.00% clean test-2 (3523 phones, 0 errors)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's enough!\n",
      "recipefilecounter 594  == collection['numlines'] 594\n",
      "pickling 3523 phones / 80521 frames to ../features/work_in_progress/en_uk_kids_align_from_clean/pickles/test-2_mcep_and_lsf.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.00% clean test-3 (4264 phones, 0 errors)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's enough!\n",
      "recipefilecounter 758  == collection['numlines'] 758\n",
      "pickling 4264 phones / 84526 frames to ../features/work_in_progress/en_uk_kids_align_from_clean/pickles/test-3_mcep_and_lsf.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.00% clean test-4 (4964 phones, 0 errors)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's enough!\n",
      "recipefilecounter 734  == collection['numlines'] 734\n",
      "pickling 4964 phones / 95555 frames to ../features/work_in_progress/en_uk_kids_align_from_clean/pickles/test-4_mcep_and_lsf.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.00% clean eval-1 (3933 phones, 0 errors)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's enough!\n",
      "recipefilecounter 393  == collection['numlines'] 393\n",
      "pickling 3933 phones / 76507 frames to ../features/work_in_progress/en_uk_kids_align_from_clean/pickles/eval-1_mcep_and_lsf.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.00% clean eval-0 (4819 phones, 0 errors)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's enough!\n",
      "recipefilecounter 837  == collection['numlines'] 837\n",
      "pickling 4819 phones / 103396 frames to ../features/work_in_progress/en_uk_kids_align_from_clean/pickles/eval-0_mcep_and_lsf.pickle\n"
     ]
    }
   ],
   "source": [
    "print (\"start!\")\n",
    "\n",
    "debug=False\n",
    "\n",
    "#print (preprocessing_scripts)\n",
    "\n",
    "for collection in collections:\n",
    "    extract_collection_and_save(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-0\n"
     ]
    }
   ],
   "source": [
    "print(collection['name'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle/save ##\n",
    "\n",
    "Next we'll save the audio data into variable length tensor flow thingies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
